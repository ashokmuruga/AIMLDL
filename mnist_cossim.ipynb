{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Copy of mnist-cossim.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashokmuruga/AIMLDL/blob/master/mnist_cossim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Customizing the convolution operation of a Conv2D layer\n",
        "\n",
        "**Author:** [Raphael Pisoni](https://www.rpisoni.dev/)  \n",
        "**Date created:** 17/01/2022  \n",
        "**Last modified:** 19/01/2022  \n",
        "**Description:** Shows how to reach 99% accuracy in MNIST with less than 1,400 parameters using Sharpened Cosine Similarity layers."
      ],
      "metadata": {
        "id": "jN9TfuhZyVbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow.keras.layers as layers"
      ],
      "metadata": {
        "id": "PmS_-fRRyVb5",
        "execution": {
          "iopub.status.busy": "2022-01-19T15:45:18.091607Z",
          "iopub.execute_input": "2022-01-19T15:45:18.091893Z",
          "iopub.status.idle": "2022-01-19T15:45:18.096508Z",
          "shell.execute_reply.started": "2022-01-19T15:45:18.091862Z",
          "shell.execute_reply": "2022-01-19T15:45:18.095794Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Prepare the data\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalization not necessary with Sharpened Cosine Similarity\n",
        "x_train = x_train.astype(\"float32\")\n",
        "x_test = x_test.astype(\"float32\")\n",
        "\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "3RZUlN4kyVb9",
        "outputId": "950a2c3c-43ac-4165-e8fb-c3c0093a8665",
        "execution": {
          "iopub.status.busy": "2022-01-19T15:45:18.108457Z",
          "iopub.execute_input": "2022-01-19T15:45:18.108934Z",
          "iopub.status.idle": "2022-01-19T15:45:18.444885Z",
          "shell.execute_reply.started": "2022-01-19T15:45:18.108902Z",
          "shell.execute_reply": "2022-01-19T15:45:18.444091Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CosSim2D(layers.Layer):\n",
        "    def __init__(self, kernel_size, units=32, stride=1, depthwise_separable=False, padding='valid'):\n",
        "        super(CosSim2D, self).__init__()\n",
        "        self.depthwise_separable = depthwise_separable\n",
        "        self.units = units\n",
        "        assert kernel_size in [1, 3, 5], \"kernel of this size not supported\"\n",
        "        self.kernel_size = kernel_size\n",
        "        if self.kernel_size == 1:\n",
        "            self.stack = lambda x: x\n",
        "        elif self.kernel_size == 3:\n",
        "            self.stack = self.stack3x3\n",
        "        elif self.kernel_size == 5:\n",
        "            self.stack = self.stack5x5\n",
        "        self.stride = stride\n",
        "        if padding == 'same':\n",
        "            self.pad = self.kernel_size // 2\n",
        "            self.pad_1 = 1\n",
        "            self.clip = 0\n",
        "        elif padding == 'valid':\n",
        "            self.pad = 0\n",
        "            self.pad_1 = 0\n",
        "            self.clip = self.kernel_size // 2\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.in_shape = input_shape\n",
        "        self.out_y = math.ceil((self.in_shape[1] - 2*self.clip) / self.stride)\n",
        "        self.out_x = math.ceil((self.in_shape[2] - 2*self.clip) / self.stride)\n",
        "        self.flat_size = self.out_x * self.out_y\n",
        "        self.channels = self.in_shape[3]\n",
        "        \n",
        "        if self.depthwise_separable:\n",
        "            self.w = self.add_weight(\n",
        "                shape=(1, tf.square(self.kernel_size), self.units),\n",
        "                initializer=\"glorot_uniform\", name='w',\n",
        "                trainable=True,\n",
        "            )\n",
        "        else:\n",
        "            self.w = self.add_weight(\n",
        "                shape=(1, self.channels * tf.square(self.kernel_size), self.units),\n",
        "                initializer=\"glorot_uniform\", name='w',\n",
        "                trainable=True,\n",
        "            )\n",
        "\n",
        "        self.b = self.add_weight(\n",
        "            shape=(self.units,), initializer=\"zeros\", trainable=True, name='b')\n",
        "\n",
        "        p_init = tf.keras.initializers.Constant(value=2)\n",
        "\n",
        "        self.p = self.add_weight(\n",
        "            shape=(self.units,), initializer=p_init, trainable=True, name='p')\n",
        "        \n",
        "    @tf.function\n",
        "    def l2_normal(self, x, axis=None, epsilon=1e-12):\n",
        "        square_sum = tf.reduce_sum(tf.square(x), axis, keepdims=True)\n",
        "        x_inv_norm = tf.sqrt(tf.maximum(square_sum, epsilon))\n",
        "        return x_inv_norm\n",
        "\n",
        "    @tf.function\n",
        "    def sigplus(self, x):\n",
        "        return tf.nn.sigmoid(x) * tf.nn.softplus(x)\n",
        "\n",
        "    @tf.function\n",
        "    def stack3x3(self, image):\n",
        "        x = tf.shape(image)[2]\n",
        "        y = tf.shape(image)[1]\n",
        "        stack = tf.stack(\n",
        "            [\n",
        "                tf.pad(image[:, :y-1-self.clip:, :x-1-self.clip, :], tf.constant([[0,0], [self.pad,0], [self.pad,0], [0,0]]))[:,::self.stride,::self.stride,:],   # top row\n",
        "                tf.pad(image[:, :y-1-self.clip, self.clip:x-self.clip, :],   tf.constant([[0,0], [self.pad,0], [0,0], [0,0]]))[:,::self.stride,::self.stride,:],\n",
        "                tf.pad(image[:, :y-1-self.clip, 1+self.clip:, :],  tf.constant([[0,0], [self.pad,0], [0,self.pad], [0,0]]))[:,::self.stride,::self.stride,:],\n",
        "                \n",
        "                tf.pad(image[:, self.clip:y-self.clip, :x-1-self.clip, :],   tf.constant([[0,0], [0,0], [self.pad,0], [0,0]]))[:,::self.stride,::self.stride,:],   # middle row\n",
        "                image[:,self.clip:y-self.clip:self.stride,self.clip:x-self.clip:self.stride,:],\n",
        "                tf.pad(image[:, self.clip:y-self.clip, 1+self.clip:, :],    tf.constant([[0,0], [0,0], [0,self.pad], [0,0]]))[:,::self.stride,::self.stride,:],\n",
        "                    \n",
        "                tf.pad(image[:, 1+self.clip:, :x-1-self.clip, :],  tf.constant([[0,0], [0,self.pad], [self.pad,0], [0,0]]))[:,::self.stride,::self.stride,:],    # bottom row\n",
        "                tf.pad(image[:, 1+self.clip:, self.clip:x-self.clip, :],    tf.constant([[0,0], [0,self.pad], [0,0], [0,0]]))[:,::self.stride,::self.stride,:],\n",
        "                tf.pad(image[:, 1+self.clip:, 1+self.clip:, :],   tf.constant([[0,0], [0,self.pad], [0,self.pad], [0,0]]))[:,::self.stride,::self.stride,:]\n",
        "            ], axis=3)\n",
        "        return stack\n",
        "    \n",
        "    @tf.function\n",
        "    def stack5x5(self, image):\n",
        "        x = tf.shape(image)[2]\n",
        "        y = tf.shape(image)[1]\n",
        "        stack = tf.stack(\n",
        "            [\n",
        "                tf.pad(image[:, :y-2-self.clip:, :x-2-self.clip, :],          tf.constant([[0,0], [self.pad,0], [self.pad,0], [0,0]]))[:,::self.stride,::self.stride,:],\n",
        "                tf.pad(image[:, :y-2-self.clip:, 1:x-1-self.clip, :],         tf.constant([[0,0], [self.pad,0], [self.pad_1,self.pad_1], [0,0]]))[:,::self.stride,::self.stride,:],\n",
        "                tf.pad(image[:, :y-2-self.clip:, self.clip:x-self.clip  , :], tf.constant([[0,0], [self.pad,0], [0,0], [0,0]]))[:,::self.stride,::self.stride,:],\n",
        "                tf.pad(image[:, :y-2-self.clip:, 1+self.clip:-1 , :],         tf.constant([[0,0], [self.pad,0], [self.pad_1,self.pad_1], [0,0]]))[:,::self.stride,::self.stride,:],\n",
        "                tf.pad(image[:, :y-2-self.clip:, 2+self.clip: , :],           tf.constant([[0,0], [self.pad,0], [0,self.pad], [0,0]]))[:,::self.stride,::self.stride,:],\n",
        "             \n",
        "                tf.pad(image[:, 1:y-1-self.clip:,  :x-2-self.clip, :],          tf.constant([[0,0], [self.pad_1,self.pad_1], [self.pad,0], [0,0]]))[:,::self.stride,::self.stride,:],\n",
        "                tf.pad(image[:, 1:y-1-self.clip:,  1:x-1-self.clip, :],         tf.constant([[0,0], [self.pad_1,self.pad_1], [self.pad_1,self.pad_1], [0,0]]))[:,::self.stride,::self.stride,:],\n",
        "                tf.pad(image[:, 1:y-1-self.clip:,  self.clip:x-self.clip  , :], tf.constant([[0,0], [self.pad_1,self.pad_1], [0,0], [0,0]]))[:,::self.stride,::self.stride,:],\n",
        "                tf.pad(image[:, 1:y-1-self.clip:, 1+self.clip:-1  , :],         tf.constant([[0,0], [self.pad_1,self.pad_1], [self.pad_1,self.pad_1], [0,0]]))[:,::self.stride,::self.stride,:],\n",
        "                tf.pad(image[:, 1:y-1-self.clip:, 2+self.clip:  , :],           tf.constant([[0,0], [self.pad_1,self.pad_1], [0,self.pad], [0,0]]))[:,::self.stride,::self.stride,:],\n",
        "                \n",
        "                tf.pad(image[:, self.clip:y-self.clip,  :x-2-self.clip, :],      tf.constant([[0,0], [0,0], [self.pad,0], [0,0]]))[:,::self.stride,::self.stride,:],\n",
        "                tf.pad(image[:, self.clip:y-self.clip,  1:x-1-self.clip, :],     tf.constant([[0,0], [0,0], [self.pad_1,self.pad_1], [0,0]]))[:,::self.stride,::self.stride,:],\n",
        "                       image[:, self.clip:y-self.clip,  self.clip:x-self.clip , :][:,::self.stride,::self.stride,:],\n",
        "                tf.pad(image[:, self.clip:y-self.clip, 1+self.clip:-1  , :],     tf.constant([[0,0], [0,0], [self.pad_1,self.pad_1], [0,0]]))[:,::self.stride,::self.stride,:],\n",
        "                tf.pad(image[:, self.clip:y-self.clip, 2+self.clip:  , :],       tf.constant([[0,0], [0,0], [0,self.pad], [0,0]]))[:,::self.stride,::self.stride,:],\n",
        "                    \n",
        "                tf.pad(image[:, 1+self.clip:-1,  :x-2-self.clip, :],           tf.constant([[0,0], [self.pad_1,self.pad_1], [self.pad,0], [0,0]]))[:,::self.stride,::self.stride,:],\n",
        "                tf.pad(image[:, 1+self.clip:-1,  1:x-1-self.clip, :],          tf.constant([[0,0], [self.pad_1,self.pad_1], [self.pad_1,self.pad_1], [0,0]]))[:,::self.stride,::self.stride,:],\n",
        "                tf.pad(image[:, 1+self.clip:-1,  self.clip:x-self.clip  , :],  tf.constant([[0,0], [self.pad_1,self.pad_1], [0,0], [0,0]]))[:,::self.stride,::self.stride,:],\n",
        "                tf.pad(image[:, 1+self.clip:-1, 1+self.clip:-1  , :],          tf.constant([[0,0], [self.pad_1,self.pad_1], [self.pad_1,self.pad_1], [0,0]]))[:,::self.stride,::self.stride,:],\n",
        "                tf.pad(image[:, 1+self.clip:-1, 2+self.clip:  , :],            tf.constant([[0,0], [self.pad_1,self.pad_1], [0,self.pad], [0,0]]))[:,::self.stride,::self.stride,:],\n",
        "                    \n",
        "                tf.pad(image[:, 2+self.clip:,  :x-2-self.clip, :],           tf.constant([[0,0], [0,self.pad], [self.pad,0], [0,0]]))[:,::self.stride,::self.stride,:],\n",
        "                tf.pad(image[:, 2+self.clip:,  1:x-1-self.clip, :],          tf.constant([[0,0], [0,self.pad], [self.pad_1,self.pad_1], [0,0]]))[:,::self.stride,::self.stride,:],\n",
        "                tf.pad(image[:, 2+self.clip:,  self.clip:x-self.clip  , :],  tf.constant([[0,0], [0,self.pad], [0,0], [0,0]]))[:,::self.stride,::self.stride,:],\n",
        "                tf.pad(image[:, 2+self.clip:, 1+self.clip:-1  , :],          tf.constant([[0,0], [0,self.pad], [self.pad_1,self.pad_1], [0,0]]))[:,::self.stride,::self.stride,:],\n",
        "                tf.pad(image[:, 2+self.clip:, 2+self.clip:  , :],            tf.constant([[0,0], [0,self.pad], [0,self.pad], [0,0]]))[:,::self.stride,::self.stride,:],\n",
        "            ], axis=3)\n",
        "        return stack\n",
        "    \n",
        "    def call_body(self, inputs):\n",
        "        channels = tf.shape(inputs)[-1]\n",
        "        x = self.stack(inputs)\n",
        "        x = tf.reshape(x, (-1, self.flat_size, channels * tf.square(self.kernel_size)))\n",
        "        x_norm = (self.l2_normal(x, axis=2))\n",
        "        w_norm = (self.l2_normal(self.w, axis=1))\n",
        "        x = tf.matmul(x / x_norm, self.w / w_norm)\n",
        "        sign = tf.sign(x)\n",
        "        x = tf.abs(x) + 1e-12\n",
        "        x = tf.pow(x  + self.sigplus(self.b), self.sigplus(self.p))\n",
        "        x = sign * x\n",
        "        x = tf.reshape(x, (-1, self.out_y, self.out_x, self.units))\n",
        "        return x\n",
        "    \n",
        "    @tf.function\n",
        "    def call(self, inputs, training=None):\n",
        "        if self.depthwise_separable:\n",
        "            channels = tf.shape(inputs)[-1]\n",
        "            x = tf.vectorized_map(self.call_body, tf.expand_dims(tf.transpose(inputs, (3,0,1,2)), axis=-1))\n",
        "            s = tf.shape(x)\n",
        "            x = tf.transpose(x, (1,2,3,4,0))\n",
        "            x = tf.reshape(x, (-1, self.out_y, self.out_x, self.channels * self.units))\n",
        "            return x\n",
        "        else:\n",
        "            x = self.call_body(inputs)\n",
        "            return x"
      ],
      "metadata": {
        "id": "woF6lhCtyVb7",
        "execution": {
          "iopub.status.busy": "2022-01-19T15:45:18.446796Z",
          "iopub.execute_input": "2022-01-19T15:45:18.447218Z",
          "iopub.status.idle": "2022-01-19T15:45:18.517412Z",
          "shell.execute_reply.started": "2022-01-19T15:45:18.447177Z",
          "shell.execute_reply": "2022-01-19T15:45:18.516554Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MaxAbsPool2D(layers.Layer):\n",
        "    def __init__(self, pool_size, pad_to_fit=False):\n",
        "        super(MaxAbsPool2D, self).__init__()\n",
        "        self.pad = pad_to_fit\n",
        "        self.pool_size = pool_size\n",
        "        \n",
        "    def compute_output_shape(self, in_shape):\n",
        "        if self.pad:\n",
        "            return (in_shape[0], \n",
        "                    tf.math.ceil(in_shape[1] / self.pool_size), \n",
        "                    tf.math.ceil(in_shape[2] / self.pool_size), \n",
        "                    in_shape[3])\n",
        "        return (in_shape[0], \n",
        "                (in_shape[1] // self.pool_size), \n",
        "                (in_shape[2] // self.pool_size), \n",
        "                in_shape[3])\n",
        "        \n",
        "    \n",
        "    def compute_padding(self, in_shape):\n",
        "        mod_y = in_shape[1] % self.pool_size\n",
        "        y1 = mod_y // 2\n",
        "        y2 = mod_y - y1\n",
        "        mod_x = in_shape[2] % self.pool_size\n",
        "        x1 = mod_x // 2\n",
        "        x2 = mod_x - x1\n",
        "        self.padding = ((0,0), (y1, y2), (x1, x2), (0,0))\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.in_shape = input_shape\n",
        "        self.out_shape = self.compute_output_shape(self.in_shape)\n",
        "        self.compute_padding(self.in_shape)\n",
        "    \n",
        "    @tf.function\n",
        "    def stack(self, inputs):\n",
        "        if self.pad:\n",
        "            inputs = tf.pad(inputs, self.padding)\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        max_height = (tf.shape(inputs)[1] // self.pool_size) * self.pool_size\n",
        "        max_width = (tf.shape(inputs)[2] // self.pool_size) * self.pool_size\n",
        "        stack = tf.stack(\n",
        "            [inputs[:, i:max_height:self.pool_size, j:max_width:self.pool_size, :] \n",
        "             for i in range(self.pool_size) for j in range(self.pool_size)],\n",
        "        axis=-1)\n",
        "        return stack\n",
        "    \n",
        "    @tf.function\n",
        "    def call(self, inputs, training=None):\n",
        "        stacked = self.stack(inputs)\n",
        "        inds = tf.argmax(tf.abs(stacked), axis=-1, output_type=tf.int32)\n",
        "        ks = tf.shape(stacked)\n",
        "        idx = tf.stack([\n",
        "            *tf.meshgrid(\n",
        "                tf.range(0, ks[0]), \n",
        "                tf.range(0, ks[1]),\n",
        "                tf.range(0, ks[2]), \n",
        "                tf.range(0, ks[3]),\n",
        "                indexing='ij'\n",
        "            ), inds], \n",
        "            axis=-1)\n",
        "        \n",
        "        x = tf.gather_nd(stacked, idx)\n",
        "        x = tf.reshape(x, (-1, *self.out_shape[1:]))\n",
        "        return x"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-19T15:45:18.520522Z",
          "iopub.execute_input": "2022-01-19T15:45:18.520715Z",
          "iopub.status.idle": "2022-01-19T15:45:18.538105Z",
          "shell.execute_reply.started": "2022-01-19T15:45:18.520692Z",
          "shell.execute_reply": "2022-01-19T15:45:18.537373Z"
        },
        "trusted": true,
        "id": "r0KfHI2OFBwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        layers.InputLayer(input_shape=input_shape),\n",
        "        layers.Dropout(0.07),\n",
        "        CosSim2D(3, 10, 1, padding='valid'),\n",
        "        CosSim2D(1, 10, 1),\n",
        "        CosSim2D(1, 12, 1),\n",
        "        layers.Dropout(0.07),\n",
        "        layers.MaxPool2D((2,2)),\n",
        "        CosSim2D(3, 2, 1, depthwise_separable=True, padding='same'),\n",
        "        CosSim2D(1, 8, 1),\n",
        "        layers.Dropout(0.07),\n",
        "        layers.MaxPool2D((2,2)),\n",
        "        CosSim2D(3, 4, 1, depthwise_separable=True),\n",
        "        CosSim2D(1, 10, 1),\n",
        "        layers.Dropout(0.07),\n",
        "        MaxAbsPool2D(2, True),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(num_classes, activation=None),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "batch_size = 1024\n",
        "epochs = 200\n",
        "checkpoint_path = 'training_1/cp.ckpt'\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_dir,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True)\n",
        "\n",
        "\n",
        "lr = tf.keras.optimizers.schedules.CosineDecay(0.05, decay_steps=(x_train.shape[0] // batch_size) * epochs, alpha=0.00001)\n",
        "\n",
        "def get_lr_metric(optimizer):\n",
        "    def lr(y_true, y_pred):\n",
        "        return optimizer._decayed_lr(tf.float32)\n",
        "    return lr\n",
        "\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "model.compile(loss=loss, optimizer=optimizer, metrics=[get_lr_metric(optimizer), \"accuracy\"], run_eagerly=False)\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=[checkpoint], validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "id": "eIX0XryJbvUk",
        "outputId": "d257f788-7733-4722-90d1-4c574dee56be",
        "execution": {
          "iopub.status.busy": "2022-01-19T15:45:18.540295Z",
          "iopub.execute_input": "2022-01-19T15:45:18.540702Z",
          "iopub.status.idle": "2022-01-19T15:59:46.192291Z",
          "shell.execute_reply.started": "2022-01-19T15:45:18.540663Z",
          "shell.execute_reply": "2022-01-19T15:59:46.191467Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout (Dropout)           (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            " cos_sim2d (CosSim2D)        (None, 26, 26, 10)        110       \n",
            "                                                                 \n",
            " cos_sim2d_1 (CosSim2D)      (None, 26, 26, 10)        120       \n",
            "                                                                 \n",
            " cos_sim2d_2 (CosSim2D)      (None, 26, 26, 12)        144       \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 26, 26, 12)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 12)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " cos_sim2d_3 (CosSim2D)      (None, 13, 13, 24)        22        \n",
            "                                                                 \n",
            " cos_sim2d_4 (CosSim2D)      (None, 13, 13, 8)         208       \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 13, 13, 8)         0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 6, 6, 8)          0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " cos_sim2d_5 (CosSim2D)      (None, 4, 4, 32)          44        \n",
            "                                                                 \n",
            " cos_sim2d_6 (CosSim2D)      (None, 4, 4, 10)          340       \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 4, 4, 10)          0         \n",
            "                                                                 \n",
            " max_abs_pool2d (MaxAbsPool2  (None, 2, 2, 10)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 40)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                410       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,398\n",
            "Trainable params: 1,398\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "59/59 [==============================] - 20s 236ms/step - loss: 0.7951 - lr: 0.0500 - accuracy: 0.7329 - val_loss: 0.2380 - val_lr: 0.0500 - val_accuracy: 0.9263\n",
            "Epoch 2/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.2517 - lr: 0.0500 - accuracy: 0.9214 - val_loss: 0.1611 - val_lr: 0.0500 - val_accuracy: 0.9499\n",
            "Epoch 3/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.1826 - lr: 0.0500 - accuracy: 0.9427 - val_loss: 0.1111 - val_lr: 0.0500 - val_accuracy: 0.9657\n",
            "Epoch 4/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.1504 - lr: 0.0500 - accuracy: 0.9526 - val_loss: 0.0900 - val_lr: 0.0499 - val_accuracy: 0.9699\n",
            "Epoch 5/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.1349 - lr: 0.0499 - accuracy: 0.9582 - val_loss: 0.0879 - val_lr: 0.0499 - val_accuracy: 0.9723\n",
            "Epoch 6/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.1210 - lr: 0.0499 - accuracy: 0.9614 - val_loss: 0.0651 - val_lr: 0.0499 - val_accuracy: 0.9784\n",
            "Epoch 7/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.1108 - lr: 0.0499 - accuracy: 0.9650 - val_loss: 0.0721 - val_lr: 0.0498 - val_accuracy: 0.9761\n",
            "Epoch 8/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.1058 - lr: 0.0498 - accuracy: 0.9661 - val_loss: 0.0605 - val_lr: 0.0498 - val_accuracy: 0.9806\n",
            "Epoch 9/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.1065 - lr: 0.0498 - accuracy: 0.9666 - val_loss: 0.0702 - val_lr: 0.0497 - val_accuracy: 0.9770\n",
            "Epoch 10/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0998 - lr: 0.0497 - accuracy: 0.9688 - val_loss: 0.0603 - val_lr: 0.0497 - val_accuracy: 0.9796\n",
            "Epoch 11/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0934 - lr: 0.0496 - accuracy: 0.9706 - val_loss: 0.0570 - val_lr: 0.0496 - val_accuracy: 0.9810\n",
            "Epoch 12/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0936 - lr: 0.0496 - accuracy: 0.9699 - val_loss: 0.0552 - val_lr: 0.0495 - val_accuracy: 0.9815\n",
            "Epoch 13/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0880 - lr: 0.0495 - accuracy: 0.9720 - val_loss: 0.0534 - val_lr: 0.0495 - val_accuracy: 0.9819\n",
            "Epoch 14/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0918 - lr: 0.0494 - accuracy: 0.9707 - val_loss: 0.0516 - val_lr: 0.0494 - val_accuracy: 0.9835\n",
            "Epoch 15/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0903 - lr: 0.0493 - accuracy: 0.9714 - val_loss: 0.0540 - val_lr: 0.0493 - val_accuracy: 0.9811\n",
            "Epoch 16/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0829 - lr: 0.0492 - accuracy: 0.9734 - val_loss: 0.0492 - val_lr: 0.0492 - val_accuracy: 0.9830\n",
            "Epoch 17/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0836 - lr: 0.0491 - accuracy: 0.9736 - val_loss: 0.0497 - val_lr: 0.0491 - val_accuracy: 0.9841\n",
            "Epoch 18/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0818 - lr: 0.0490 - accuracy: 0.9748 - val_loss: 0.0493 - val_lr: 0.0490 - val_accuracy: 0.9836\n",
            "Epoch 19/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0780 - lr: 0.0489 - accuracy: 0.9760 - val_loss: 0.0515 - val_lr: 0.0489 - val_accuracy: 0.9840\n",
            "Epoch 20/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0834 - lr: 0.0488 - accuracy: 0.9738 - val_loss: 0.0451 - val_lr: 0.0487 - val_accuracy: 0.9845\n",
            "Epoch 21/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0803 - lr: 0.0487 - accuracy: 0.9748 - val_loss: 0.0488 - val_lr: 0.0486 - val_accuracy: 0.9836\n",
            "Epoch 22/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0780 - lr: 0.0485 - accuracy: 0.9747 - val_loss: 0.0483 - val_lr: 0.0485 - val_accuracy: 0.9839\n",
            "Epoch 23/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0784 - lr: 0.0484 - accuracy: 0.9747 - val_loss: 0.0477 - val_lr: 0.0483 - val_accuracy: 0.9841\n",
            "Epoch 24/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0791 - lr: 0.0483 - accuracy: 0.9751 - val_loss: 0.0489 - val_lr: 0.0482 - val_accuracy: 0.9828\n",
            "Epoch 25/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0780 - lr: 0.0481 - accuracy: 0.9751 - val_loss: 0.0479 - val_lr: 0.0480 - val_accuracy: 0.9835\n",
            "Epoch 26/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0772 - lr: 0.0480 - accuracy: 0.9755 - val_loss: 0.0496 - val_lr: 0.0479 - val_accuracy: 0.9842\n",
            "Epoch 27/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0757 - lr: 0.0478 - accuracy: 0.9765 - val_loss: 0.0556 - val_lr: 0.0477 - val_accuracy: 0.9812\n",
            "Epoch 28/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0766 - lr: 0.0476 - accuracy: 0.9760 - val_loss: 0.0484 - val_lr: 0.0475 - val_accuracy: 0.9842\n",
            "Epoch 29/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0710 - lr: 0.0475 - accuracy: 0.9776 - val_loss: 0.0429 - val_lr: 0.0474 - val_accuracy: 0.9861\n",
            "Epoch 30/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0731 - lr: 0.0473 - accuracy: 0.9766 - val_loss: 0.0416 - val_lr: 0.0472 - val_accuracy: 0.9848\n",
            "Epoch 31/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0739 - lr: 0.0471 - accuracy: 0.9765 - val_loss: 0.0411 - val_lr: 0.0470 - val_accuracy: 0.9864\n",
            "Epoch 32/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0706 - lr: 0.0469 - accuracy: 0.9777 - val_loss: 0.0399 - val_lr: 0.0468 - val_accuracy: 0.9872\n",
            "Epoch 33/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0718 - lr: 0.0467 - accuracy: 0.9771 - val_loss: 0.0507 - val_lr: 0.0466 - val_accuracy: 0.9832\n",
            "Epoch 34/200\n",
            "59/59 [==============================] - 12s 196ms/step - loss: 0.0710 - lr: 0.0465 - accuracy: 0.9772 - val_loss: 0.0468 - val_lr: 0.0464 - val_accuracy: 0.9852\n",
            "Epoch 35/200\n",
            "59/59 [==============================] - 12s 199ms/step - loss: 0.0701 - lr: 0.0463 - accuracy: 0.9774 - val_loss: 0.0386 - val_lr: 0.0462 - val_accuracy: 0.9875\n",
            "Epoch 36/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0674 - lr: 0.0461 - accuracy: 0.9785 - val_loss: 0.0470 - val_lr: 0.0460 - val_accuracy: 0.9854\n",
            "Epoch 37/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0686 - lr: 0.0459 - accuracy: 0.9773 - val_loss: 0.0507 - val_lr: 0.0458 - val_accuracy: 0.9825\n",
            "Epoch 38/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0710 - lr: 0.0456 - accuracy: 0.9775 - val_loss: 0.0405 - val_lr: 0.0455 - val_accuracy: 0.9864\n",
            "Epoch 39/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0659 - lr: 0.0454 - accuracy: 0.9795 - val_loss: 0.0380 - val_lr: 0.0453 - val_accuracy: 0.9876\n",
            "Epoch 40/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0655 - lr: 0.0452 - accuracy: 0.9793 - val_loss: 0.0421 - val_lr: 0.0451 - val_accuracy: 0.9851\n",
            "Epoch 41/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0656 - lr: 0.0449 - accuracy: 0.9795 - val_loss: 0.0423 - val_lr: 0.0448 - val_accuracy: 0.9857\n",
            "Epoch 42/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0670 - lr: 0.0447 - accuracy: 0.9782 - val_loss: 0.0372 - val_lr: 0.0446 - val_accuracy: 0.9882\n",
            "Epoch 43/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0654 - lr: 0.0445 - accuracy: 0.9797 - val_loss: 0.0463 - val_lr: 0.0443 - val_accuracy: 0.9833\n",
            "Epoch 44/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0656 - lr: 0.0442 - accuracy: 0.9789 - val_loss: 0.0386 - val_lr: 0.0441 - val_accuracy: 0.9867\n",
            "Epoch 45/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0645 - lr: 0.0439 - accuracy: 0.9794 - val_loss: 0.0388 - val_lr: 0.0438 - val_accuracy: 0.9866\n",
            "Epoch 46/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0665 - lr: 0.0437 - accuracy: 0.9786 - val_loss: 0.0373 - val_lr: 0.0435 - val_accuracy: 0.9882\n",
            "Epoch 47/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0622 - lr: 0.0434 - accuracy: 0.9803 - val_loss: 0.0394 - val_lr: 0.0433 - val_accuracy: 0.9864\n",
            "Epoch 48/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0617 - lr: 0.0431 - accuracy: 0.9803 - val_loss: 0.0365 - val_lr: 0.0430 - val_accuracy: 0.9873\n",
            "Epoch 49/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0619 - lr: 0.0429 - accuracy: 0.9796 - val_loss: 0.0415 - val_lr: 0.0427 - val_accuracy: 0.9853\n",
            "Epoch 50/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0633 - lr: 0.0426 - accuracy: 0.9803 - val_loss: 0.0358 - val_lr: 0.0424 - val_accuracy: 0.9878\n",
            "Epoch 51/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0619 - lr: 0.0423 - accuracy: 0.9802 - val_loss: 0.0416 - val_lr: 0.0421 - val_accuracy: 0.9865\n",
            "Epoch 52/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0607 - lr: 0.0420 - accuracy: 0.9809 - val_loss: 0.0371 - val_lr: 0.0419 - val_accuracy: 0.9867\n",
            "Epoch 53/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0654 - lr: 0.0417 - accuracy: 0.9797 - val_loss: 0.0387 - val_lr: 0.0416 - val_accuracy: 0.9870\n",
            "Epoch 54/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0609 - lr: 0.0414 - accuracy: 0.9807 - val_loss: 0.0389 - val_lr: 0.0413 - val_accuracy: 0.9864\n",
            "Epoch 55/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0619 - lr: 0.0411 - accuracy: 0.9802 - val_loss: 0.0346 - val_lr: 0.0410 - val_accuracy: 0.9885\n",
            "Epoch 56/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0587 - lr: 0.0408 - accuracy: 0.9816 - val_loss: 0.0360 - val_lr: 0.0406 - val_accuracy: 0.9881\n",
            "Epoch 57/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0597 - lr: 0.0405 - accuracy: 0.9803 - val_loss: 0.0428 - val_lr: 0.0403 - val_accuracy: 0.9852\n",
            "Epoch 58/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0635 - lr: 0.0402 - accuracy: 0.9803 - val_loss: 0.0360 - val_lr: 0.0400 - val_accuracy: 0.9869\n",
            "Epoch 59/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0587 - lr: 0.0398 - accuracy: 0.9807 - val_loss: 0.0389 - val_lr: 0.0397 - val_accuracy: 0.9862\n",
            "Epoch 60/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0607 - lr: 0.0395 - accuracy: 0.9808 - val_loss: 0.0380 - val_lr: 0.0394 - val_accuracy: 0.9881\n",
            "Epoch 61/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0577 - lr: 0.0392 - accuracy: 0.9811 - val_loss: 0.0389 - val_lr: 0.0390 - val_accuracy: 0.9865\n",
            "Epoch 62/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0600 - lr: 0.0389 - accuracy: 0.9807 - val_loss: 0.0408 - val_lr: 0.0387 - val_accuracy: 0.9862\n",
            "Epoch 63/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0599 - lr: 0.0385 - accuracy: 0.9810 - val_loss: 0.0402 - val_lr: 0.0384 - val_accuracy: 0.9868\n",
            "Epoch 64/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0580 - lr: 0.0382 - accuracy: 0.9819 - val_loss: 0.0354 - val_lr: 0.0380 - val_accuracy: 0.9880\n",
            "Epoch 65/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0587 - lr: 0.0379 - accuracy: 0.9815 - val_loss: 0.0369 - val_lr: 0.0377 - val_accuracy: 0.9880\n",
            "Epoch 66/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0599 - lr: 0.0375 - accuracy: 0.9813 - val_loss: 0.0397 - val_lr: 0.0373 - val_accuracy: 0.9864\n",
            "Epoch 67/200\n",
            "59/59 [==============================] - 12s 196ms/step - loss: 0.0588 - lr: 0.0372 - accuracy: 0.9815 - val_loss: 0.0364 - val_lr: 0.0370 - val_accuracy: 0.9876\n",
            "Epoch 68/200\n",
            "59/59 [==============================] - 12s 196ms/step - loss: 0.0576 - lr: 0.0368 - accuracy: 0.9813 - val_loss: 0.0382 - val_lr: 0.0366 - val_accuracy: 0.9876\n",
            "Epoch 69/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0577 - lr: 0.0365 - accuracy: 0.9820 - val_loss: 0.0352 - val_lr: 0.0363 - val_accuracy: 0.9891\n",
            "Epoch 70/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0571 - lr: 0.0361 - accuracy: 0.9813 - val_loss: 0.0340 - val_lr: 0.0359 - val_accuracy: 0.9888\n",
            "Epoch 71/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0583 - lr: 0.0357 - accuracy: 0.9809 - val_loss: 0.0361 - val_lr: 0.0356 - val_accuracy: 0.9881\n",
            "Epoch 72/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0588 - lr: 0.0354 - accuracy: 0.9804 - val_loss: 0.0382 - val_lr: 0.0352 - val_accuracy: 0.9882\n",
            "Epoch 73/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0560 - lr: 0.0350 - accuracy: 0.9822 - val_loss: 0.0329 - val_lr: 0.0348 - val_accuracy: 0.9886\n",
            "Epoch 74/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0558 - lr: 0.0346 - accuracy: 0.9816 - val_loss: 0.0381 - val_lr: 0.0345 - val_accuracy: 0.9872\n",
            "Epoch 75/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0550 - lr: 0.0343 - accuracy: 0.9823 - val_loss: 0.0388 - val_lr: 0.0341 - val_accuracy: 0.9878\n",
            "Epoch 76/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0562 - lr: 0.0339 - accuracy: 0.9824 - val_loss: 0.0341 - val_lr: 0.0337 - val_accuracy: 0.9884\n",
            "Epoch 77/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0565 - lr: 0.0335 - accuracy: 0.9819 - val_loss: 0.0378 - val_lr: 0.0333 - val_accuracy: 0.9874\n",
            "Epoch 78/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0564 - lr: 0.0332 - accuracy: 0.9818 - val_loss: 0.0371 - val_lr: 0.0330 - val_accuracy: 0.9879\n",
            "Epoch 79/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0550 - lr: 0.0328 - accuracy: 0.9825 - val_loss: 0.0361 - val_lr: 0.0326 - val_accuracy: 0.9887\n",
            "Epoch 80/200\n",
            "59/59 [==============================] - 12s 208ms/step - loss: 0.0540 - lr: 0.0324 - accuracy: 0.9827 - val_loss: 0.0402 - val_lr: 0.0322 - val_accuracy: 0.9873\n",
            "Epoch 81/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0547 - lr: 0.0320 - accuracy: 0.9823 - val_loss: 0.0344 - val_lr: 0.0318 - val_accuracy: 0.9887\n",
            "Epoch 82/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0524 - lr: 0.0316 - accuracy: 0.9835 - val_loss: 0.0344 - val_lr: 0.0314 - val_accuracy: 0.9893\n",
            "Epoch 83/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0552 - lr: 0.0312 - accuracy: 0.9823 - val_loss: 0.0349 - val_lr: 0.0311 - val_accuracy: 0.9885\n",
            "Epoch 84/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0544 - lr: 0.0309 - accuracy: 0.9827 - val_loss: 0.0379 - val_lr: 0.0307 - val_accuracy: 0.9875\n",
            "Epoch 85/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0550 - lr: 0.0305 - accuracy: 0.9824 - val_loss: 0.0370 - val_lr: 0.0303 - val_accuracy: 0.9877\n",
            "Epoch 86/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0553 - lr: 0.0301 - accuracy: 0.9824 - val_loss: 0.0364 - val_lr: 0.0299 - val_accuracy: 0.9882\n",
            "Epoch 87/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0529 - lr: 0.0297 - accuracy: 0.9832 - val_loss: 0.0386 - val_lr: 0.0295 - val_accuracy: 0.9885\n",
            "Epoch 88/200\n",
            "59/59 [==============================] - 12s 199ms/step - loss: 0.0542 - lr: 0.0293 - accuracy: 0.9830 - val_loss: 0.0353 - val_lr: 0.0291 - val_accuracy: 0.9897\n",
            "Epoch 89/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0530 - lr: 0.0289 - accuracy: 0.9829 - val_loss: 0.0374 - val_lr: 0.0287 - val_accuracy: 0.9880\n",
            "Epoch 90/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0514 - lr: 0.0285 - accuracy: 0.9833 - val_loss: 0.0364 - val_lr: 0.0283 - val_accuracy: 0.9893\n",
            "Epoch 91/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0540 - lr: 0.0281 - accuracy: 0.9824 - val_loss: 0.0356 - val_lr: 0.0279 - val_accuracy: 0.9890\n",
            "Epoch 92/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0520 - lr: 0.0277 - accuracy: 0.9836 - val_loss: 0.0369 - val_lr: 0.0275 - val_accuracy: 0.9882\n",
            "Epoch 93/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0514 - lr: 0.0273 - accuracy: 0.9836 - val_loss: 0.0340 - val_lr: 0.0271 - val_accuracy: 0.9891\n",
            "Epoch 94/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0515 - lr: 0.0269 - accuracy: 0.9838 - val_loss: 0.0417 - val_lr: 0.0267 - val_accuracy: 0.9862\n",
            "Epoch 95/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0515 - lr: 0.0265 - accuracy: 0.9833 - val_loss: 0.0356 - val_lr: 0.0263 - val_accuracy: 0.9883\n",
            "Epoch 96/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0506 - lr: 0.0261 - accuracy: 0.9838 - val_loss: 0.0374 - val_lr: 0.0259 - val_accuracy: 0.9875\n",
            "Epoch 97/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0519 - lr: 0.0257 - accuracy: 0.9833 - val_loss: 0.0374 - val_lr: 0.0255 - val_accuracy: 0.9889\n",
            "Epoch 98/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0526 - lr: 0.0253 - accuracy: 0.9829 - val_loss: 0.0402 - val_lr: 0.0251 - val_accuracy: 0.9874\n",
            "Epoch 99/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0499 - lr: 0.0249 - accuracy: 0.9841 - val_loss: 0.0377 - val_lr: 0.0247 - val_accuracy: 0.9877\n",
            "Epoch 100/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0517 - lr: 0.0245 - accuracy: 0.9835 - val_loss: 0.0332 - val_lr: 0.0243 - val_accuracy: 0.9894\n",
            "Epoch 101/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0505 - lr: 0.0241 - accuracy: 0.9833 - val_loss: 0.0345 - val_lr: 0.0239 - val_accuracy: 0.9888\n",
            "Epoch 102/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0518 - lr: 0.0237 - accuracy: 0.9834 - val_loss: 0.0340 - val_lr: 0.0235 - val_accuracy: 0.9895\n",
            "Epoch 103/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0501 - lr: 0.0233 - accuracy: 0.9838 - val_loss: 0.0358 - val_lr: 0.0231 - val_accuracy: 0.9881\n",
            "Epoch 104/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0506 - lr: 0.0229 - accuracy: 0.9836 - val_loss: 0.0372 - val_lr: 0.0227 - val_accuracy: 0.9887\n",
            "Epoch 105/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0496 - lr: 0.0225 - accuracy: 0.9841 - val_loss: 0.0369 - val_lr: 0.0223 - val_accuracy: 0.9871\n",
            "Epoch 106/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0513 - lr: 0.0221 - accuracy: 0.9833 - val_loss: 0.0334 - val_lr: 0.0219 - val_accuracy: 0.9899\n",
            "Epoch 107/200\n",
            "59/59 [==============================] - 12s 208ms/step - loss: 0.0489 - lr: 0.0217 - accuracy: 0.9844 - val_loss: 0.0331 - val_lr: 0.0215 - val_accuracy: 0.9899\n",
            "Epoch 108/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0485 - lr: 0.0213 - accuracy: 0.9845 - val_loss: 0.0353 - val_lr: 0.0211 - val_accuracy: 0.9891\n",
            "Epoch 109/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0510 - lr: 0.0209 - accuracy: 0.9835 - val_loss: 0.0330 - val_lr: 0.0207 - val_accuracy: 0.9891\n",
            "Epoch 110/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0488 - lr: 0.0205 - accuracy: 0.9843 - val_loss: 0.0350 - val_lr: 0.0204 - val_accuracy: 0.9901\n",
            "Epoch 111/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0491 - lr: 0.0202 - accuracy: 0.9840 - val_loss: 0.0343 - val_lr: 0.0200 - val_accuracy: 0.9892\n",
            "Epoch 112/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0487 - lr: 0.0198 - accuracy: 0.9839 - val_loss: 0.0332 - val_lr: 0.0196 - val_accuracy: 0.9887\n",
            "Epoch 113/200\n",
            "59/59 [==============================] - 12s 196ms/step - loss: 0.0471 - lr: 0.0194 - accuracy: 0.9850 - val_loss: 0.0343 - val_lr: 0.0192 - val_accuracy: 0.9890\n",
            "Epoch 114/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0482 - lr: 0.0190 - accuracy: 0.9844 - val_loss: 0.0341 - val_lr: 0.0188 - val_accuracy: 0.9885\n",
            "Epoch 115/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0468 - lr: 0.0186 - accuracy: 0.9846 - val_loss: 0.0339 - val_lr: 0.0184 - val_accuracy: 0.9892\n",
            "Epoch 116/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0477 - lr: 0.0182 - accuracy: 0.9847 - val_loss: 0.0345 - val_lr: 0.0180 - val_accuracy: 0.9891\n",
            "Epoch 117/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0486 - lr: 0.0178 - accuracy: 0.9846 - val_loss: 0.0352 - val_lr: 0.0176 - val_accuracy: 0.9886\n",
            "Epoch 118/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0481 - lr: 0.0174 - accuracy: 0.9841 - val_loss: 0.0322 - val_lr: 0.0173 - val_accuracy: 0.9892\n",
            "Epoch 119/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0468 - lr: 0.0171 - accuracy: 0.9845 - val_loss: 0.0347 - val_lr: 0.0169 - val_accuracy: 0.9889\n",
            "Epoch 120/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0489 - lr: 0.0167 - accuracy: 0.9839 - val_loss: 0.0364 - val_lr: 0.0165 - val_accuracy: 0.9890\n",
            "Epoch 121/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0494 - lr: 0.0163 - accuracy: 0.9839 - val_loss: 0.0339 - val_lr: 0.0161 - val_accuracy: 0.9885\n",
            "Epoch 122/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0469 - lr: 0.0159 - accuracy: 0.9848 - val_loss: 0.0404 - val_lr: 0.0158 - val_accuracy: 0.9864\n",
            "Epoch 123/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0462 - lr: 0.0156 - accuracy: 0.9844 - val_loss: 0.0336 - val_lr: 0.0154 - val_accuracy: 0.9896\n",
            "Epoch 124/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0463 - lr: 0.0152 - accuracy: 0.9852 - val_loss: 0.0326 - val_lr: 0.0150 - val_accuracy: 0.9894\n",
            "Epoch 125/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0466 - lr: 0.0148 - accuracy: 0.9845 - val_loss: 0.0344 - val_lr: 0.0147 - val_accuracy: 0.9885\n",
            "Epoch 126/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0489 - lr: 0.0145 - accuracy: 0.9842 - val_loss: 0.0369 - val_lr: 0.0143 - val_accuracy: 0.9882\n",
            "Epoch 127/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0484 - lr: 0.0141 - accuracy: 0.9835 - val_loss: 0.0334 - val_lr: 0.0139 - val_accuracy: 0.9899\n",
            "Epoch 128/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0489 - lr: 0.0138 - accuracy: 0.9838 - val_loss: 0.0336 - val_lr: 0.0136 - val_accuracy: 0.9895\n",
            "Epoch 129/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0460 - lr: 0.0134 - accuracy: 0.9852 - val_loss: 0.0351 - val_lr: 0.0132 - val_accuracy: 0.9888\n",
            "Epoch 130/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0464 - lr: 0.0130 - accuracy: 0.9850 - val_loss: 0.0317 - val_lr: 0.0129 - val_accuracy: 0.9894\n",
            "Epoch 131/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0461 - lr: 0.0127 - accuracy: 0.9857 - val_loss: 0.0322 - val_lr: 0.0125 - val_accuracy: 0.9895\n",
            "Epoch 132/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0447 - lr: 0.0124 - accuracy: 0.9850 - val_loss: 0.0328 - val_lr: 0.0122 - val_accuracy: 0.9892\n",
            "Epoch 133/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0460 - lr: 0.0120 - accuracy: 0.9852 - val_loss: 0.0312 - val_lr: 0.0118 - val_accuracy: 0.9896\n",
            "Epoch 134/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0462 - lr: 0.0117 - accuracy: 0.9843 - val_loss: 0.0334 - val_lr: 0.0115 - val_accuracy: 0.9885\n",
            "Epoch 135/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0449 - lr: 0.0113 - accuracy: 0.9854 - val_loss: 0.0331 - val_lr: 0.0112 - val_accuracy: 0.9893\n",
            "Epoch 136/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0462 - lr: 0.0110 - accuracy: 0.9848 - val_loss: 0.0336 - val_lr: 0.0108 - val_accuracy: 0.9890\n",
            "Epoch 137/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0441 - lr: 0.0107 - accuracy: 0.9851 - val_loss: 0.0351 - val_lr: 0.0105 - val_accuracy: 0.9882\n",
            "Epoch 138/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0466 - lr: 0.0103 - accuracy: 0.9848 - val_loss: 0.0332 - val_lr: 0.0102 - val_accuracy: 0.9901\n",
            "Epoch 139/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0450 - lr: 0.0100 - accuracy: 0.9856 - val_loss: 0.0332 - val_lr: 0.0099 - val_accuracy: 0.9894\n",
            "Epoch 140/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0461 - lr: 0.0097 - accuracy: 0.9849 - val_loss: 0.0341 - val_lr: 0.0095 - val_accuracy: 0.9885\n",
            "Epoch 141/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0446 - lr: 0.0094 - accuracy: 0.9858 - val_loss: 0.0338 - val_lr: 0.0092 - val_accuracy: 0.9888\n",
            "Epoch 142/200\n",
            "59/59 [==============================] - 12s 209ms/step - loss: 0.0437 - lr: 0.0091 - accuracy: 0.9855 - val_loss: 0.0347 - val_lr: 0.0089 - val_accuracy: 0.9892\n",
            "Epoch 143/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0444 - lr: 0.0088 - accuracy: 0.9857 - val_loss: 0.0330 - val_lr: 0.0086 - val_accuracy: 0.9892\n",
            "Epoch 144/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0450 - lr: 0.0085 - accuracy: 0.9850 - val_loss: 0.0314 - val_lr: 0.0083 - val_accuracy: 0.9894\n",
            "Epoch 145/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0455 - lr: 0.0082 - accuracy: 0.9854 - val_loss: 0.0326 - val_lr: 0.0080 - val_accuracy: 0.9886\n",
            "Epoch 146/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0435 - lr: 0.0079 - accuracy: 0.9857 - val_loss: 0.0332 - val_lr: 0.0077 - val_accuracy: 0.9885\n",
            "Epoch 147/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0451 - lr: 0.0076 - accuracy: 0.9852 - val_loss: 0.0322 - val_lr: 0.0075 - val_accuracy: 0.9887\n",
            "Epoch 148/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0442 - lr: 0.0073 - accuracy: 0.9855 - val_loss: 0.0330 - val_lr: 0.0072 - val_accuracy: 0.9893\n",
            "Epoch 149/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0452 - lr: 0.0070 - accuracy: 0.9848 - val_loss: 0.0318 - val_lr: 0.0069 - val_accuracy: 0.9894\n",
            "Epoch 150/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0432 - lr: 0.0068 - accuracy: 0.9858 - val_loss: 0.0333 - val_lr: 0.0066 - val_accuracy: 0.9898\n",
            "Epoch 151/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0444 - lr: 0.0065 - accuracy: 0.9854 - val_loss: 0.0327 - val_lr: 0.0064 - val_accuracy: 0.9900\n",
            "Epoch 152/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0434 - lr: 0.0062 - accuracy: 0.9859 - val_loss: 0.0329 - val_lr: 0.0061 - val_accuracy: 0.9886\n",
            "Epoch 153/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0437 - lr: 0.0060 - accuracy: 0.9860 - val_loss: 0.0337 - val_lr: 0.0058 - val_accuracy: 0.9888\n",
            "Epoch 154/200\n",
            "59/59 [==============================] - 12s 199ms/step - loss: 0.0434 - lr: 0.0057 - accuracy: 0.9855 - val_loss: 0.0325 - val_lr: 0.0056 - val_accuracy: 0.9898\n",
            "Epoch 155/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0427 - lr: 0.0054 - accuracy: 0.9860 - val_loss: 0.0321 - val_lr: 0.0053 - val_accuracy: 0.9888\n",
            "Epoch 156/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0436 - lr: 0.0052 - accuracy: 0.9860 - val_loss: 0.0323 - val_lr: 0.0051 - val_accuracy: 0.9891\n",
            "Epoch 157/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0431 - lr: 0.0050 - accuracy: 0.9856 - val_loss: 0.0319 - val_lr: 0.0048 - val_accuracy: 0.9896\n",
            "Epoch 158/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0436 - lr: 0.0047 - accuracy: 0.9856 - val_loss: 0.0318 - val_lr: 0.0046 - val_accuracy: 0.9893\n",
            "Epoch 159/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0430 - lr: 0.0045 - accuracy: 0.9862 - val_loss: 0.0331 - val_lr: 0.0044 - val_accuracy: 0.9895\n",
            "Epoch 160/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0436 - lr: 0.0043 - accuracy: 0.9860 - val_loss: 0.0316 - val_lr: 0.0042 - val_accuracy: 0.9892\n",
            "Epoch 161/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0426 - lr: 0.0040 - accuracy: 0.9856 - val_loss: 0.0321 - val_lr: 0.0039 - val_accuracy: 0.9891\n",
            "Epoch 162/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0425 - lr: 0.0038 - accuracy: 0.9858 - val_loss: 0.0322 - val_lr: 0.0037 - val_accuracy: 0.9895\n",
            "Epoch 163/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0430 - lr: 0.0036 - accuracy: 0.9866 - val_loss: 0.0319 - val_lr: 0.0035 - val_accuracy: 0.9891\n",
            "Epoch 164/200\n",
            "59/59 [==============================] - 12s 199ms/step - loss: 0.0410 - lr: 0.0034 - accuracy: 0.9867 - val_loss: 0.0324 - val_lr: 0.0033 - val_accuracy: 0.9895\n",
            "Epoch 165/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0419 - lr: 0.0032 - accuracy: 0.9863 - val_loss: 0.0317 - val_lr: 0.0031 - val_accuracy: 0.9895\n",
            "Epoch 166/200\n",
            "59/59 [==============================] - 12s 199ms/step - loss: 0.0436 - lr: 0.0030 - accuracy: 0.9854 - val_loss: 0.0306 - val_lr: 0.0029 - val_accuracy: 0.9895\n",
            "Epoch 167/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0427 - lr: 0.0028 - accuracy: 0.9859 - val_loss: 0.0309 - val_lr: 0.0027 - val_accuracy: 0.9901\n",
            "Epoch 168/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0406 - lr: 0.0027 - accuracy: 0.9864 - val_loss: 0.0309 - val_lr: 0.0026 - val_accuracy: 0.9898\n",
            "Epoch 169/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0419 - lr: 0.0025 - accuracy: 0.9862 - val_loss: 0.0309 - val_lr: 0.0024 - val_accuracy: 0.9891\n",
            "Epoch 170/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0428 - lr: 0.0023 - accuracy: 0.9859 - val_loss: 0.0312 - val_lr: 0.0022 - val_accuracy: 0.9892\n",
            "Epoch 171/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0422 - lr: 0.0021 - accuracy: 0.9863 - val_loss: 0.0326 - val_lr: 0.0021 - val_accuracy: 0.9889\n",
            "Epoch 172/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0425 - lr: 0.0020 - accuracy: 0.9862 - val_loss: 0.0311 - val_lr: 0.0019 - val_accuracy: 0.9891\n",
            "Epoch 173/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0419 - lr: 0.0018 - accuracy: 0.9863 - val_loss: 0.0317 - val_lr: 0.0018 - val_accuracy: 0.9893\n",
            "Epoch 174/200\n",
            "59/59 [==============================] - 12s 199ms/step - loss: 0.0414 - lr: 0.0017 - accuracy: 0.9863 - val_loss: 0.0316 - val_lr: 0.0016 - val_accuracy: 0.9895\n",
            "Epoch 175/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0410 - lr: 0.0015 - accuracy: 0.9862 - val_loss: 0.0321 - val_lr: 0.0015 - val_accuracy: 0.9887\n",
            "Epoch 176/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0412 - lr: 0.0014 - accuracy: 0.9865 - val_loss: 0.0315 - val_lr: 0.0013 - val_accuracy: 0.9892\n",
            "Epoch 177/200\n",
            "59/59 [==============================] - 12s 199ms/step - loss: 0.0429 - lr: 0.0013 - accuracy: 0.9861 - val_loss: 0.0312 - val_lr: 0.0012 - val_accuracy: 0.9893\n",
            "Epoch 178/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0424 - lr: 0.0012 - accuracy: 0.9861 - val_loss: 0.0315 - val_lr: 0.0011 - val_accuracy: 0.9895\n",
            "Epoch 179/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0422 - lr: 0.0010 - accuracy: 0.9865 - val_loss: 0.0311 - val_lr: 9.8372e-04 - val_accuracy: 0.9894\n",
            "Epoch 180/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0410 - lr: 9.2837e-04 - accuracy: 0.9869 - val_loss: 0.0314 - val_lr: 8.7587e-04 - val_accuracy: 0.9901\n",
            "Epoch 181/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0411 - lr: 8.2364e-04 - accuracy: 0.9864 - val_loss: 0.0316 - val_lr: 7.7417e-04 - val_accuracy: 0.9895\n",
            "Epoch 182/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0407 - lr: 7.2509e-04 - accuracy: 0.9865 - val_loss: 0.0312 - val_lr: 6.7866e-04 - val_accuracy: 0.9893\n",
            "Epoch 183/200\n",
            "59/59 [==============================] - 12s 199ms/step - loss: 0.0402 - lr: 6.3273e-04 - accuracy: 0.9874 - val_loss: 0.0317 - val_lr: 5.8935e-04 - val_accuracy: 0.9895\n",
            "Epoch 184/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0419 - lr: 5.4659e-04 - accuracy: 0.9864 - val_loss: 0.0313 - val_lr: 5.0628e-04 - val_accuracy: 0.9894\n",
            "Epoch 185/200\n",
            "59/59 [==============================] - 12s 197ms/step - loss: 0.0414 - lr: 4.6670e-04 - accuracy: 0.9858 - val_loss: 0.0312 - val_lr: 4.2947e-04 - val_accuracy: 0.9894\n",
            "Epoch 186/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0415 - lr: 3.9307e-04 - accuracy: 0.9860 - val_loss: 0.0311 - val_lr: 3.5892e-04 - val_accuracy: 0.9894\n",
            "Epoch 187/200\n",
            "59/59 [==============================] - 12s 199ms/step - loss: 0.0414 - lr: 3.2573e-04 - accuracy: 0.9862 - val_loss: 0.0310 - val_lr: 2.9467e-04 - val_accuracy: 0.9897\n",
            "Epoch 188/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0412 - lr: 2.6468e-04 - accuracy: 0.9861 - val_loss: 0.0311 - val_lr: 2.3673e-04 - val_accuracy: 0.9896\n",
            "Epoch 189/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0405 - lr: 2.0995e-04 - accuracy: 0.9871 - val_loss: 0.0310 - val_lr: 1.8511e-04 - val_accuracy: 0.9897\n",
            "Epoch 190/200\n",
            "59/59 [==============================] - 12s 199ms/step - loss: 0.0405 - lr: 1.6155e-04 - accuracy: 0.9868 - val_loss: 0.0309 - val_lr: 1.3982e-04 - val_accuracy: 0.9898\n",
            "Epoch 191/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0411 - lr: 1.1949e-04 - accuracy: 0.9869 - val_loss: 0.0309 - val_lr: 1.0088e-04 - val_accuracy: 0.9899\n",
            "Epoch 192/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0407 - lr: 8.3784e-05 - accuracy: 0.9868 - val_loss: 0.0308 - val_lr: 6.8300e-05 - val_accuracy: 0.9899\n",
            "Epoch 193/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0406 - lr: 5.4439e-05 - accuracy: 0.9862 - val_loss: 0.0308 - val_lr: 4.2084e-05 - val_accuracy: 0.9898\n",
            "Epoch 194/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0420 - lr: 3.1463e-05 - accuracy: 0.9862 - val_loss: 0.0308 - val_lr: 2.2241e-05 - val_accuracy: 0.9898\n",
            "Epoch 195/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0415 - lr: 1.4861e-05 - accuracy: 0.9862 - val_loss: 0.0308 - val_lr: 8.7745e-06 - val_accuracy: 0.9898\n",
            "Epoch 196/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0400 - lr: 4.6392e-06 - accuracy: 0.9870 - val_loss: 0.0308 - val_lr: 1.6876e-06 - val_accuracy: 0.9898\n",
            "Epoch 197/200\n",
            "59/59 [==============================] - 12s 198ms/step - loss: 0.0405 - lr: 7.3162e-07 - accuracy: 0.9865 - val_loss: 0.0308 - val_lr: 5.0000e-07 - val_accuracy: 0.9898\n",
            "Epoch 198/200\n",
            "59/59 [==============================] - 12s 199ms/step - loss: 0.0410 - lr: 5.0000e-07 - accuracy: 0.9863 - val_loss: 0.0308 - val_lr: 5.0000e-07 - val_accuracy: 0.9898\n",
            "Epoch 199/200\n",
            "59/59 [==============================] - 12s 199ms/step - loss: 0.0401 - lr: 5.0000e-07 - accuracy: 0.9869 - val_loss: 0.0308 - val_lr: 5.0000e-07 - val_accuracy: 0.9898\n",
            "Epoch 200/200\n",
            "59/59 [==============================] - 12s 199ms/step - loss: 0.0410 - lr: 5.0000e-07 - accuracy: 0.9868 - val_loss: 0.0308 - val_lr: 5.0000e-07 - val_accuracy: 0.9898\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5c0027efd0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(checkpoint_dir)\n",
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "RaErqAhUnXSM",
        "execution": {
          "iopub.status.busy": "2022-01-19T15:59:46.193860Z",
          "iopub.execute_input": "2022-01-19T15:59:46.194140Z",
          "iopub.status.idle": "2022-01-19T15:59:48.884086Z",
          "shell.execute_reply.started": "2022-01-19T15:59:46.194102Z",
          "shell.execute_reply": "2022-01-19T15:59:48.883396Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba7cff29-bc41-4e74-fdba-921d123380e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0350 - lr: 0.0204 - accuracy: 0.9901\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0349777415394783, 0.020355693995952606, 0.9901000261306763]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, layer in enumerate(model.layers):\n",
        "    if layer.name.startswith('cos_sim2d'):\n",
        "        kernel_layer = i\n",
        "        break\n",
        "        \n",
        "_, axs = plt.subplots(2, 5, figsize=(20, 10))\n",
        "axs = axs.flatten()\n",
        "\n",
        "kernels = []\n",
        "\n",
        "for i, ax in zip(range(tf.shape(model.layers[kernel_layer].w)[-1]), axs):\n",
        "    kernel = model.layers[kernel_layer].w[0,:, i]\n",
        "    side = tf.sqrt(tf.cast(tf.shape(kernel)[0], tf.float32))\n",
        "    kernel = tf.reshape(kernel, (side,side,1)).numpy()\n",
        "    kernels.append(kernel)\n",
        "    ax.imshow(kernel[:,:,0], vmin=-1, vmax=1)\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vy5EpGG6yc4a",
        "execution": {
          "iopub.status.busy": "2022-01-19T15:59:48.885345Z",
          "iopub.execute_input": "2022-01-19T15:59:48.885680Z",
          "iopub.status.idle": "2022-01-19T15:59:49.389180Z",
          "shell.execute_reply.started": "2022-01-19T15:59:48.885641Z",
          "shell.execute_reply": "2022-01-19T15:59:49.388465Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "outputId": "788165e6-acef-4e15-b965-80f2a1843062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 10 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = 9\n",
        "print(layer)\n",
        "plt.imshow(x_test[n][:,:,0])\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "activations = layer(x_test[n:n+1])[0].numpy()\n",
        "\n",
        "_, axs = plt.subplots(nrows=activations.shape[-1], ncols=2, figsize=(15, activations.shape[-1] * 8))\n",
        "\n",
        "for i in range(10):\n",
        "    axs[i, 0].imshow(activations[:,:,i], vmin=-1, vmax=1)\n",
        "    axs[i, 0].axis('off')\n",
        "    axs[i, 1].imshow(kernels[i][:,:,0], vmin=-1, vmax=1)\n",
        "    axs[i, 1].axis('off')\n",
        "plt.tight_layout\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-19T15:59:49.390558Z",
          "iopub.execute_input": "2022-01-19T15:59:49.390961Z",
          "iopub.status.idle": "2022-01-19T15:59:50.713940Z",
          "shell.execute_reply.started": "2022-01-19T15:59:49.390918Z",
          "shell.execute_reply": "2022-01-19T15:59:50.713228Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wpmhNbwFFBwL",
        "outputId": "f3f5f85e-deb7-4c29-9f5a-8d3e47bd2e6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<__main__.CosSim2D object at 0x7f5c0f1f8790>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x5760 with 20 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2TaPRR_QVeF8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}