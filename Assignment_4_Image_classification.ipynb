{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_4_Image_classification.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashokmuruga/AIMLDL/blob/master/Assignment_4_Image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FbVhjPpzn6BM"
      },
      "source": [
        "First run the following cells to import current version of Tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jL3OqFKZ9dFg",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEtC-uS5bimo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.0.0-beta1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dzLKpmZICaWN",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yR0EdgrLCaWR"
      },
      "source": [
        "## Import the Image dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DLdCchMdCaWQ"
      },
      "source": [
        "In this notebook, we are going to classify images from the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset. \n",
        "\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://miro.medium.com/max/479/1*yBdJCRwIJGoM7pwU-LNW6Q.png\"\n",
        "         alt=\"CIFAR samples\"  >\n",
        "  </td></tr>\n",
        "  <tr><td align=\"center\">\n",
        "    <b>Figure 1.</b> <a href=\"http://yann.lecun.com/exdb/mnist/\">MNIST samples</a>.<br/>&nbsp;\n",
        "  </td></tr>\n",
        "</table>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7MqDQO0KCaWS",
        "colab": {}
      },
      "source": [
        "tf.random.set_seed(100)\n",
        "mnist = keras.datasets.mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IjnLH5S2CaWx",
        "colab": {}
      },
      "source": [
        "num_train, img_rows, img_cols =  train_images.shape\n",
        "num_test, _, _ =  test_images.shape\n",
        "num_classes = len(np.unique(train_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Brm0b_KACaWX"
      },
      "source": [
        "## Explore the data\n",
        "\n",
        "#### Q1: What is the shape of train and test data in MNIST dataset?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFVmt6TFg_wc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images.shape\n",
        "test_images.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ES6uQoLKCaWr"
      },
      "source": [
        "## Preprocess the data\n",
        "\n",
        "The data must be preprocessed before training the network. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bW5WzIPlCaWv",
        "colab": {}
      },
      "source": [
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "59veuiEZCaW4"
      },
      "source": [
        "## Build the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Gxg1XGm0eOBy"
      },
      "source": [
        "Model should contain following layers:\n",
        "  \n",
        "  Flatten(Input) -> Dense(10, activation='softmax')\n",
        "  \n",
        "Use 'Adam' optimizer\n",
        "\n",
        "Use 'accuracy' as your metric\n",
        "\n",
        "#### Q2: Which loss function would be appropriate here? \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7-4xb8v7T8-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=keras.Sequential([keras.layers.Flatten(input_shape=(28,28)),\n",
        "                       keras.layers.Dense(300,activation='relu'),\n",
        "                       keras.layers.Dense(10,activation='softmax')])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit(train_images,train_labels,epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hvanZPNkXivG"
      },
      "source": [
        "Model should contain following layers:\n",
        "  \n",
        "  Flatten(Input) -> Dense(10, activation='softmax')\n",
        "  \n",
        "Use 'Adam' optimizer\n",
        "\n",
        "Use 'accuracy' as your metric\n",
        "\n",
        "#### Q2: Which loss function would be appropriate here? \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwCOzzGM8nqL",
        "colab_type": "text"
      },
      "source": [
        "#### Q3: Total number of **parameters**? \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qKF6uW-BCaW-"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "Run the following command to train your model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xvwvpA64CaW_",
        "colab": {}
      },
      "source": [
        "history = model.fit(train_images, train_labels, batch_size=512, validation_data = (test_images, test_labels), epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQqKtmyu8ws2",
        "colab_type": "text"
      },
      "source": [
        "Run the above command before answering Q4.\n",
        "\n",
        "Modify the model and run the above code answer Q5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NL8MnimTcBit",
        "colab_type": "text"
      },
      "source": [
        "## Test Underfitting and Overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7iTdt4dcGhR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# summarize history for accuracy\n",
        "def plot_acc(history):\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()\n",
        "# summarize history for loss\n",
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmagO0XOeKss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_acc(history)\n",
        "plot_loss(history)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}